{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4a3814",
   "metadata": {},
   "source": [
    "### Gamma Band (70-100 Hz) Scalogram Generation\n",
    "\n",
    "# This notebook provides a function to generate a scalogram focused specifically on the\n",
    "# high-frequency gamma band. It takes a 1D EEG signal, applies CWT, and saves the\n",
    "# scalogram as an image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b3bf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8200f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "def save_wpt_scalogram(signal, sampling_rate, output_path, wavelet='db4', maxlevel=5):\n",
    "    \"\"\"\n",
    "    Performs Wavelet Packet Decomposition (WPT), \n",
    "    creates a scalogram-like image, and saves it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Wavelet Packet Decomposition\n",
    "        wp = pywt.WaveletPacket(data=signal, wavelet=wavelet, maxlevel=maxlevel)\n",
    "        \n",
    "        # Get all nodes at the chosen level\n",
    "        nodes = wp.get_level(maxlevel, order='freq')\n",
    "        freqs = np.linspace(0, sampling_rate/2, len(nodes))  # Approx frequency mapping\n",
    "        coeff_matrix = np.array([node.data for node in nodes])\n",
    "        \n",
    "        # Convert to magnitude (energy-like representation)\n",
    "        coeff_matrix = np.abs(coeff_matrix)\n",
    "        \n",
    "        # Create and save plot\n",
    "        fig, ax = plt.subplots(figsize=(1.28, 1.28))\n",
    "        ax.imshow(coeff_matrix, aspect='auto', cmap='viridis', \n",
    "                  extent=[0, len(signal), freqs[0], freqs[-1]])\n",
    "        ax.axis('off')\n",
    "        plt.savefig(output_path, bbox_inches='tight', pad_inches=0, dpi=100)\n",
    "        plt.close(fig)\n",
    "\n",
    "        return {'success': True, 'output_path': output_path}\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {'success': False, 'error': str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af87f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "# --- Step 2: Setup Paths ---\n",
    "normalized_data_dir = r'D:\\\\VIT\\\\IV-Year\\\\PJT-I\\\\Speech Imagery Decoding\\\\Inner_Speech_Dataset\\\\Dataset\\\\filtered_data_regex'\n",
    "scalogram_output_dir = r'D:\\\\VIT\\\\IV-Year\\\\PJT-I\\\\Speech Imagery Decoding\\\\Inner_Speech_Dataset\\\\Dataset\\\\scalogram'\n",
    "os.makedirs(scalogram_output_dir, exist_ok=True)\n",
    "\n",
    "SAMPLING_RATE = 256  # Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61fa3b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43120 files to process...\n"
     ]
    }
   ],
   "source": [
    "# Cell 4\n",
    "# --- Step 3: Collect Files ---\n",
    "file_metadata_list = []\n",
    "for root, _, files in os.walk(normalized_data_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.npy'):\n",
    "            full_path = os.path.join(root, file)\n",
    "            \n",
    "            # --- MODIFIED PART ---\n",
    "            # Extract trial and channel from filename to create the new structure\n",
    "            base_name = os.path.splitext(file)[0]\n",
    "            try:\n",
    "                # Split the filename to separate the trial identifier from the channel\n",
    "                trial_folder_name, channel_name = base_name.rsplit('_', 1)\n",
    "                \n",
    "                # Create the output path: output_dir/trial_folder/channel.png\n",
    "                output_folder = os.path.join(scalogram_output_dir, trial_folder_name)\n",
    "                output_filename = channel_name + '.png'\n",
    "                output_file = os.path.join(output_folder, output_filename)\n",
    "                \n",
    "                # Ensure the directory for the trial exists\n",
    "                os.makedirs(output_folder, exist_ok=True)\n",
    "                \n",
    "                file_metadata_list.append((full_path, output_file, SAMPLING_RATE))\n",
    "            except ValueError:\n",
    "                # This will happen if the filename doesn't contain an underscore to split on\n",
    "                print(f\"Warning: Could not parse trial and channel from filename: {file}. Skipping this file.\")\n",
    "            # --- END OF MODIFIED PART ---\n",
    "            \n",
    "print(f\"Found {len(file_metadata_list)} files to process...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb4a585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c7d47f1359414a8cc5d4836a84a558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scalograms:   0%|          | 0/43120 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 5\n",
    "# --- Step 4: Sequential Processing (No multiprocessing) ---\n",
    "results = []\n",
    "for file_info in tqdm(file_metadata_list, desc=\"Scalograms\", unit=\"file\"):\n",
    "    source_path, output_path, sampling_rate = file_info\n",
    "    try:\n",
    "        signal = np.load(source_path)\n",
    "        if signal.ndim != 1:\n",
    "            signal = signal.flatten()\n",
    "        result = save_wpt_scalogram(signal, sampling_rate, output_path)\n",
    "    except Exception as e:\n",
    "        result = {'success': False, 'error': f\"Failed {source_path}: {e}\"}\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1510ef76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PROCESSING COMPLETE ===\n",
      "✓ Successfully processed: 43120 files\n",
      "✗ Failed: 0 files\n",
      "Success rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Cell 6\n",
    "# --- Step 5: Collect Metadata ---\n",
    "processed_metadata = []\n",
    "success_count = sum(1 for r in results if r['success'])\n",
    "fail_count = len(results) - success_count\n",
    "\n",
    "for file_info, result in zip(file_metadata_list, results):\n",
    "    source_path, output_path, _ = file_info\n",
    "    row = {'file_path': source_path, 'output_path': output_path}\n",
    "    row.update(result)\n",
    "    processed_metadata.append(row)\n",
    "\n",
    "processed_df = pd.DataFrame(processed_metadata)\n",
    "\n",
    "# --- Step 6: Report ---\n",
    "print(\"\\n=== PROCESSING COMPLETE ===\")\n",
    "print(f\"✓ Successfully processed: {success_count} files\")\n",
    "print(f\"✗ Failed: {fail_count} files\")\n",
    "if (success_count + fail_count) > 0:\n",
    "    print(f\"Success rate: {(success_count / (success_count + fail_count)) * 100:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
